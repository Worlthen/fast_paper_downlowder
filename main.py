"""
å­¦æœ¯è®ºæ–‡è‡ªåŠ¨ä¸‹è½½å™¨ - ä¸»ç¨‹åº
æä¾›ç”¨æˆ·å‹å¥½çš„å‘½ä»¤è¡Œç•Œé¢
"""

import os
import sys
import asyncio
import click
from pathlib import Path
from typing import List, Optional
from loguru import logger
import yaml
from datetime import datetime

from config import LOG_FORMAT, SUPPORTED_PLATFORMS
from paper_parser import PaperListParser
from coordinator import PaperDownloaderCoordinator, SearchConfig, DownloadConfig


# é…ç½®æ—¥å¿—
def setup_logging(level: str = "INFO", log_file: Optional[str] = None):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    
    # æ§åˆ¶å°æ—¥å¿—
    logger.add(
        sys.stdout,
        format=LOG_FORMAT,
        level=level,
        colorize=True
    )
    
    # æ–‡ä»¶æ—¥å¿—
    if log_file:
        logger.add(
            log_file,
            format=LOG_FORMAT,
            level=level,
            rotation="10 MB",
            retention="10 days",
            compression="zip"
        )


# åŠ è½½é…ç½®æ–‡ä»¶
def load_config(config_file: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_file}")
        return config
    except Exception as e:
        logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ {config_file}: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return {}


# éªŒè¯è¾“å…¥æ–‡ä»¶
def validate_input_file(input_file: str) -> bool:
    """éªŒè¯è¾“å…¥æ–‡ä»¶"""
    if not os.path.exists(input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return False
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    supported_extensions = ['.txt', '.csv', '.xlsx', '.xls', '.json']
    file_ext = Path(input_file).suffix.lower()
    
    if file_ext not in supported_extensions:
        logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        logger.info(f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_extensions)}")
        return False
    
    return True








@click.command()
@click.option(
    '--input', '-i',
    required=True,
    type=click.Path(exists=True, readable=True, dir_okay=False),
    help='åŒ…å«è®ºæ–‡æ ‡é¢˜çš„è¾“å…¥æ–‡ä»¶è·¯å¾„ (.txt, .csv, .xlsx, .xls, .json)ã€‚'
)
@click.option(
    '--output', '-o',
    default='./downloads',
    type=click.Path(file_okay=False, resolve_path=True),
    help='ä¸‹è½½è®ºæ–‡çš„è¾“å‡ºç›®å½•ã€‚'
)
@click.option(
    '--log-level', '-l',
    default='INFO',
    type=click.Choice(['DEBUG', 'INFO', 'WARNING', 'ERROR']),
    help='è®¾ç½®æ—¥å¿—è®°å½•çº§åˆ«ã€‚'
)
@click.option(
    '--log-file',
    type=click.Path(dir_okay=False),
    help='å°†æ—¥å¿—è¾“å‡ºåˆ°æŒ‡å®šæ–‡ä»¶ã€‚'
)
@click.option(
    '--proxy',
    is_flag=True,
    help='å¯ç”¨åœ¨ config.yaml ä¸­é…ç½®çš„ç½‘ç»œä»£ç†ã€‚'
)
@click.version_option(version='1.0.0', prog_name='Fast Paper Downloader')
def main(input: str, output: str, log_level: str, log_file: Optional[str], proxy: bool):
    """
    ä¸€ä¸ªæ ¹æ®æ ‡é¢˜è‡ªåŠ¨ä¸‹è½½è®ºæ–‡çš„å‘½ä»¤è¡Œå·¥å…·ã€‚
    """
    # 1. é…ç½®æ—¥å¿—
    setup_logging(log_level, log_file)
    logger.info("Fast Paper Downloader å¯åŠ¨")

    # 2. éªŒè¯è¾“å…¥æ–‡ä»¶
    if not validate_input_file(input):
        sys.exit(1)

    # 3. åŠ è½½å¹¶é…ç½®ä»£ç†
    if proxy:
        # æ³¨æ„ï¼šé…ç½®æ–‡ä»¶è·¯å¾„æ˜¯ç¡¬ç¼–ç çš„ï¼Œä»¥ç®€åŒ–æ“ä½œ
        config = load_config('config.yaml')
        if 'proxy' in config and config.get('proxy'):
            http_proxy = config['proxy'].get('http')
            https_proxy = config['proxy'].get('https')
            
            if http_proxy:
                os.environ['HTTP_PROXY'] = http_proxy
            if https_proxy:
                os.environ['HTTPS_PROXY'] = https_proxy

            if http_proxy or https_proxy:
                logger.info("å·²å¯ç”¨ç½‘ç»œä»£ç†ã€‚")
            else:
                logger.warning("ä»£ç†æ ‡å¿—å·²è®¾ç½®ï¼Œä½†åœ¨ config.yaml ä¸­æœªæ‰¾åˆ°æœ‰æ•ˆçš„ http/https ä»£ç†é…ç½®ã€‚")
        else:
            logger.warning("ä»£ç†æ ‡å¿—å·²è®¾ç½®ï¼Œä½†åœ¨ config.yaml ä¸­æœªæ‰¾åˆ°ä»£ç†é…ç½®ã€‚")

    # 4. åˆ›å»ºæœç´¢å’Œä¸‹è½½é…ç½®ï¼ˆä½¿ç”¨ç¡¬ç¼–ç çš„ç®€åŒ–å€¼ï¼‰
    search_config = SearchConfig(
        platforms=SUPPORTED_PLATFORMS,  # ä½¿ç”¨æ‰€æœ‰æ”¯æŒçš„å¹³å°
        max_results_per_platform=5,     # æ¯ä¸ªå¹³å°æœ€å¤š5ä¸ªç»“æœ
        use_async=True                  # å§‹ç»ˆä½¿ç”¨å¼‚æ­¥æ¨¡å¼
    )
    
    download_config = DownloadConfig(
        output_dir=output,
        max_concurrent_downloads=5,     # ç¡¬ç¼–ç å¹¶å‘æ•°
        overwrite_existing=False,       # ä¸è¦†ç›–ç°æœ‰æ–‡ä»¶
        save_metadata=True              # ä¿å­˜å…ƒæ•°æ®
    )

    # 5. åˆå§‹åŒ–ä¸‹è½½åè°ƒå™¨
    coordinator = PaperDownloaderCoordinator(search_config, download_config)
    
    logger.info(f"è¾“å…¥æ–‡ä»¶: {input}")
    logger.info(f"è¾“å‡ºç›®å½•: {os.path.abspath(output)}")
    logger.info("ğŸš€ å¼€å§‹å¤„ç†è®ºæ–‡åˆ—è¡¨...")

    # 6. è¿è¡Œä¸»ä¸‹è½½ç¨‹åº
    try:
        report = asyncio.run(coordinator.process_paper_list(input))
        
        # 7. æ˜¾ç¤ºå®Œæˆæ‘˜è¦
        summary = report.get('summary', {})
        logger.info("=" * 60)
        logger.info("âœ… æ‰€æœ‰ä»»åŠ¡å·²å®Œæˆï¼")
        logger.info(
            f"å¤„ç†ç»“æœ: æ€»æ•°={summary.get('total_papers', 0)}, "
            f"æœç´¢æˆåŠŸ={summary.get('successful_searches', 0)}, "
            f"ä¸‹è½½æˆåŠŸ={summary.get('successful_downloads', 0)}"
        )
        logger.info(f"ä¸‹è½½çš„è®ºæ–‡å·²ä¿å­˜åˆ°: {os.path.abspath(output)}")
        logger.info("=" * 60)

    except KeyboardInterrupt:
        logger.warning("ç”¨æˆ·ä¸­æ–­äº†ç¨‹åºæ‰§è¡Œã€‚")
        sys.exit(130)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡ŒæœŸé—´å‘ç”Ÿæ„å¤–é”™è¯¯: {e}")
        sys.exit(1)
    finally:
        try:
            coordinator.close()
        except Exception as e:
            logger.debug(f"å…³é—­åè°ƒå™¨æ—¶å‘ç”Ÿé”™è¯¯: {e}")








 


if __name__ == '__main__':
    main()
