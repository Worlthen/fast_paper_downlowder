"""
å­¦æœ¯è®ºæ–‡è‡ªåŠ¨ä¸‹è½½å™¨ - ä¸»ç¨‹åº
æä¾›ç”¨æˆ·å‹å¥½çš„å‘½ä»¤è¡Œç•Œé¢
"""

import os
import sys
import asyncio
import click
from pathlib import Path
from typing import List, Optional
from loguru import logger
import yaml
from datetime import datetime

from config import LOG_FORMAT, SUPPORTED_PLATFORMS
from paper_parser import PaperListParser
from coordinator import PaperDownloaderCoordinator, SearchConfig, DownloadConfig


# é…ç½®æ—¥å¿—
def setup_logging(level: str = "INFO", log_file: Optional[str] = None):
    """è®¾ç½®æ—¥å¿—é…ç½®"""
    logger.remove()  # ç§»é™¤é»˜è®¤å¤„ç†å™¨
    
    # æ§åˆ¶å°æ—¥å¿—
    logger.add(
        sys.stdout,
        format=LOG_FORMAT,
        level=level,
        colorize=True
    )
    
    # æ–‡ä»¶æ—¥å¿—
    if log_file:
        logger.add(
            log_file,
            format=LOG_FORMAT,
            level=level,
            rotation="10 MB",
            retention="10 days",
            compression="zip"
        )


# åŠ è½½é…ç½®æ–‡ä»¶
def load_config(config_file: str) -> dict:
    """åŠ è½½é…ç½®æ–‡ä»¶"""
    try:
        with open(config_file, 'r', encoding='utf-8') as f:
            config = yaml.safe_load(f)
        logger.info(f"é…ç½®æ–‡ä»¶åŠ è½½æˆåŠŸ: {config_file}")
        return config
    except Exception as e:
        logger.warning(f"é…ç½®æ–‡ä»¶åŠ è½½å¤±è´¥ {config_file}: {e}ï¼Œä½¿ç”¨é»˜è®¤é…ç½®")
        return {}


# éªŒè¯è¾“å…¥æ–‡ä»¶
def validate_input_file(input_file: str) -> bool:
    """éªŒè¯è¾“å…¥æ–‡ä»¶"""
    if not os.path.exists(input_file):
        logger.error(f"è¾“å…¥æ–‡ä»¶ä¸å­˜åœ¨: {input_file}")
        return False
    
    # æ”¯æŒçš„æ–‡ä»¶æ ¼å¼
    supported_extensions = ['.txt', '.csv', '.xlsx', '.xls', '.json']
    file_ext = Path(input_file).suffix.lower()
    
    if file_ext not in supported_extensions:
        logger.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_ext}")
        logger.info(f"æ”¯æŒçš„æ ¼å¼: {', '.join(supported_extensions)}")
        return False
    
    return True


# æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
def show_welcome():
    """æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯"""
    welcome_text = """
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                    å­¦æœ¯è®ºæ–‡è‡ªåŠ¨ä¸‹è½½å™¨ Academic Paper Downloader            â•‘
â•‘                                                                              â•‘
â•‘  ğŸ” æ”¯æŒå¤šå¹³å°æœç´¢ (Google Scholar, Sci-Hub, arXiv)                         â•‘
â•‘  ğŸ“„ è‡ªåŠ¨è§£æè®ºæ–‡åˆ—è¡¨æ–‡ä»¶                                                     â•‘
â•‘  ğŸ’¾ æ‰¹é‡ä¸‹è½½PDFæ–‡ä»¶                                                         â•‘
â•‘  âš¡ å¼‚æ­¥å¤„ç†ï¼Œé«˜æ•ˆå¿«é€Ÿ                                                      â•‘
â•‘  ğŸ›¡ï¸  æ™ºèƒ½é”™è¯¯å¤„ç†å’Œé‡è¯•æœºåˆ¶                                                 â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    click.echo(welcome_text)


# æ˜¾ç¤ºå®Œæˆä¿¡æ¯
def show_completion_summary(report: dict):
    """æ˜¾ç¤ºå®Œæˆæ‘˜è¦"""
    summary = report.get('summary', {})
    
    search_success_rate_str = f"{summary.get('search_success_rate', 0):.1%}"
    download_success_rate_str = f"{summary.get('download_success_rate', 0):.1%}"

    completion_text = f"""
â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—
â•‘                              ä»»åŠ¡å®Œæˆï¼                                      â•‘
â• â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•£
â•‘  æ€»è®ºæ–‡æ•°: {summary.get('total_papers', 0):\u003c45} â•‘
â•‘  æœç´¢æˆåŠŸ: {summary.get('successful_searches', 0):\u003c45} â•‘
â•‘  æœç´¢å¤±è´¥: {summary.get('failed_searches', 0):\u003c45} â•‘
â•‘  ä¸‹è½½æˆåŠŸ: {summary.get('successful_downloads', 0):\u003c45} â•‘
â•‘  ä¸‹è½½å¤±è´¥: {summary.get('failed_downloads', 0):\u003c45} â•‘
â•‘  æœç´¢æˆåŠŸç‡: {search_success_rate_str:\u003c45} â•‘
â•‘  ä¸‹è½½æˆåŠŸç‡: {download_success_rate_str:\u003c45} â•‘
â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
    """
    click.echo(completion_text)


@click.group(invoke_without_command=True)
@click.option(
    '--input', '-i',
    required=False,
    type=click.Path(exists=True),
    help='è¾“å…¥æ–‡ä»¶è·¯å¾„ï¼ˆåŒ…å«è®ºæ–‡åˆ—è¡¨ï¼‰'
)
@click.option(
    '--output', '-o',
    default='./downloads',
    type=click.Path(),
    help='è¾“å‡ºç›®å½•è·¯å¾„ï¼ˆé»˜è®¤: ./downloadsï¼‰'
)
@click.option(
    '--config', '-c',
    type=click.Path(exists=True),
    help='é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆYAMLæ ¼å¼ï¼‰'
)
@click.option(
    '--platforms', '-p',
    default='all',
    help='æœç´¢å¹³å°ï¼Œé€—å·åˆ†éš” (google_scholar,scihub,arxiv,all) é»˜è®¤: all'
)
@click.option(
    '--max-results', '-n',
    default=5,
    type=int,
    help='æ¯ä¸ªå¹³å°æœ€å¤§æœç´¢ç»“æœæ•°ï¼ˆé»˜è®¤: 5ï¼‰'
)
@click.option(
    '--max-concurrent', '-C',
    default=3,
    type=int,
    help='æœ€å¤§å¹¶å‘ä¸‹è½½æ•°ï¼ˆé»˜è®¤: 3ï¼‰'
)
@click.option(
    '--async/--sync', 'async_mode',
    default=True,
    help='ä½¿ç”¨å¼‚æ­¥/åŒæ­¥æ¨¡å¼ï¼ˆé»˜è®¤: å¼‚æ­¥ï¼‰'
)
@click.option(
    '--overwrite/--no-overwrite',
    default=False,
    help='è¦†ç›–å·²å­˜åœ¨çš„æ–‡ä»¶ï¼ˆé»˜è®¤: ä¸è¦†ç›–ï¼‰'
)
@click.option(
    '--log-level', '-l',
    default='INFO',
    type=click.Choice(['DEBUG', 'INFO', 'WARNING', 'ERROR']),
    help='æ—¥å¿—çº§åˆ«ï¼ˆé»˜è®¤: INFOï¼‰'
)
@click.option(
    '--log-file',
    type=click.Path(),
    help='æ—¥å¿—æ–‡ä»¶è·¯å¾„'
)
@click.option(
    '--proxy',
    is_flag=True,
    help='ä½¿ç”¨ä»£ç†ï¼ˆéœ€è¦åœ¨é…ç½®æ–‡ä»¶ä¸­é…ç½®ï¼‰'
)
@click.option(
    '--test-mode',
    is_flag=True,
    help='æµ‹è¯•æ¨¡å¼ï¼ˆåªå¤„ç†å‰3ç¯‡è®ºæ–‡ï¼‰'
)
@click.option(
    '--quiet', '-q',
    is_flag=True,
    help='é™é»˜æ¨¡å¼ï¼ˆåªæ˜¾ç¤ºé”™è¯¯ä¿¡æ¯ï¼‰'
)
@click.version_option(version='1.0.0', prog_name='Academic Paper Downloader')
@click.pass_context
def main(ctx, input, output, config, platforms, max_results, max_concurrent, async_mode, 
         overwrite, log_level, log_file, proxy, test_mode, quiet):
    """
    å­¦æœ¯è®ºæ–‡è‡ªåŠ¨ä¸‹è½½å™¨
    
    è‡ªåŠ¨ä»å¤šä¸ªå­¦æœ¯å¹³å°ï¼ˆGoogle Scholarã€Sci-Hubã€arXivï¼‰æœç´¢å¹¶ä¸‹è½½PDFæ–‡ä»¶ã€‚
    
    ç¤ºä¾‹:
    
        \b
        # åŸºæœ¬ä½¿ç”¨
        python main.py -i papers.txt
        
        \b
        # æŒ‡å®šè¾“å‡ºç›®å½•å’Œå¹³å°
        python main.py -i papers.txt -o ./my_papers -p google_scholar,scihub
        
        \b
        # ä½¿ç”¨è¯¦ç»†æ—¥å¿—å’Œæµ‹è¯•æ¨¡å¼
        python main.py -i papers.txt -l DEBUG --test-mode
    """
    
    # è®¾ç½®æ—¥å¿—
    if quiet:
        log_level = 'ERROR'
    
    setup_logging(log_level, log_file)
    
    # æ˜¾ç¤ºæ¬¢è¿ä¿¡æ¯
    if not quiet:
        show_welcome()
    
    # è‹¥æœ‰å­å‘½ä»¤ï¼Œä¸»æµç¨‹ä¸æ‰§è¡Œ
    if ctx.invoked_subcommand is not None:
        return

    # è‹¥æ— å­å‘½ä»¤ï¼Œåˆ™è¦æ±‚è¾“å…¥æ–‡ä»¶
    if not input:
        click.echo('Error: éœ€è¦æä¾› --input/-i è¾“å…¥æ–‡ä»¶è·¯å¾„')
        sys.exit(2)
    # éªŒè¯è¾“å…¥æ–‡ä»¶
    if not validate_input_file(input):
        sys.exit(1)
    
    # åŠ è½½é…ç½®
    config_data = {}
    if config:
        config_data = load_config(config)
    
    # è§£æå¹³å°å‚æ•°
    if platforms == 'all':
        selected_platforms = SUPPORTED_PLATFORMS
    else:
        selected_platforms = [p.strip() for p in platforms.split(',')]
        # éªŒè¯å¹³å°åç§°
        for platform in selected_platforms:
            if platform not in SUPPORTED_PLATFORMS:
                logger.error(f"ä¸æ”¯æŒçš„å¹³å°: {platform}")
                logger.info(f"æ”¯æŒçš„å¹³å°: {', '.join(SUPPORTED_PLATFORMS)}")
                sys.exit(1)
    
    # åˆ›å»ºæœç´¢å’Œä¸‹è½½é…ç½®
    search_config = SearchConfig(
        platforms=selected_platforms,
        max_results_per_platform=max_results,
        use_async=async_mode
    )
    
    download_config = DownloadConfig(
        output_dir=output,
        max_concurrent_downloads=max_concurrent,
        overwrite_existing=overwrite,
        save_metadata=True
    )
    
    # æ˜¾ç¤ºé…ç½®ä¿¡æ¯
    if not quiet:
        click.echo("\nğŸ“‹ é…ç½®ä¿¡æ¯:")
        click.echo(f"  è¾“å…¥æ–‡ä»¶: {input}")
        click.echo(f"  è¾“å‡ºç›®å½•: {output}")
        click.echo(f"  æœç´¢å¹³å°: {', '.join(selected_platforms)}")
        click.echo(f"  æœ€å¤§ç»“æœæ•°: {max_results}")
        click.echo(f"  å¹¶å‘ä¸‹è½½æ•°: {max_concurrent}")
        click.echo(f"  å¼‚æ­¥æ¨¡å¼: {'æ˜¯' if async_mode else 'å¦'}")
        click.echo(f"  è¦†ç›–ç°æœ‰æ–‡ä»¶: {'æ˜¯' if overwrite else 'å¦'}")
        click.echo(f"  æµ‹è¯•æ¨¡å¼: {'æ˜¯' if test_mode else 'å¦'}")
        click.echo()
    
    # è¿è¡Œä¸»ç¨‹åº
    try:
        # åˆ›å»ºåè°ƒå™¨
        coordinator = PaperDownloaderCoordinator(search_config, download_config)
        
        # å¤„ç†è®ºæ–‡åˆ—è¡¨
        if not quiet:
            click.echo("ğŸš€ å¼€å§‹å¤„ç†è®ºæ–‡åˆ—è¡¨...")
        
        # è¿è¡Œå¼‚æ­¥ä¸»ç¨‹åº
        report = asyncio.run(run_main(coordinator, input, test_mode))
        
        # æ˜¾ç¤ºå®Œæˆä¿¡æ¯
        if not quiet:
            show_completion_summary(report)
        
        # ä¿å­˜æŠ¥å‘Š
        report_file = Path(output) / f"report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
        save_report(report, report_file)
        
        if not quiet:
            click.echo(f"ğŸ“Š è¯¦ç»†æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
        
    except KeyboardInterrupt:
        logger.info("ç”¨æˆ·ä¸­æ–­ç¨‹åºæ‰§è¡Œ")
        sys.exit(1)
    except Exception as e:
        logger.error(f"ç¨‹åºæ‰§è¡Œå¤±è´¥: {e}")
        sys.exit(1)
    finally:
        # æ¸…ç†èµ„æº
        try:
            coordinator.close()
        except:
            pass


async def run_main(coordinator: PaperDownloaderCoordinator, input_file: str, test_mode: bool):
    """è¿è¡Œä¸»ç¨‹åº"""
    if test_mode:
        # æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ç¯‡è®ºæ–‡
        logger.info("æµ‹è¯•æ¨¡å¼ï¼šåªå¤„ç†å‰3ç¯‡è®ºæ–‡")
        
        # è§£æè®ºæ–‡åˆ—è¡¨
        parser = PaperListParser()
        all_papers = parser.parse_file(input_file)
        
        if len(all_papers) > 3:
            test_papers = all_papers[:3]
            # ä¿å­˜æµ‹è¯•æ–‡ä»¶
            test_file = "test_papers.txt"
            parser.save_papers_list(test_papers, test_file)
            
            try:
                report = await coordinator.process_paper_list(test_file)
            finally:
                # æ¸…ç†æµ‹è¯•æ–‡ä»¶
                if os.path.exists(test_file):
                    os.remove(test_file)
        else:
            report = await coordinator.process_paper_list(input_file)
    else:
        report = await coordinator.process_paper_list(input_file)
    
    return report


def save_report(report: dict, report_file: Path):
    """ä¿å­˜æŠ¥å‘Šåˆ°æ–‡ä»¶"""
    try:
        import json
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, ensure_ascii=False, indent=2)
        logger.info(f"æŠ¥å‘Šå·²ä¿å­˜åˆ°: {report_file}")
    except Exception as e:
        logger.error(f"ä¿å­˜æŠ¥å‘Šå¤±è´¥: {e}")


 


if __name__ == '__main__':
    main()
